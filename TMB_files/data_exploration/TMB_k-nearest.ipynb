{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'nba_2013.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bd48a639bdc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nba_2013.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mnba_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnba_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# The names of all the columns in the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nba_2013.csv'"
     ]
    }
   ],
   "source": [
    "#k-nearest; origin: https://www.dataquest.io/blog/k-nearest-neighbors-in-python/\n",
    "import math\n",
    "import pandas\n",
    "with open(\"data/nba_2013.csv\", 'r') as csvfile:\n",
    "    nba_df = pandas.read_csv(csvfile)\n",
    "print(nba_df.columns.values) # The names of all the columns in the data.\n",
    "\n",
    "# Select Lebron James from our dataset\n",
    "selected_player = nba_df[nba_df[\"player\"] == \"LeBron James\"].iloc[0]\n",
    "\n",
    "# Choose only the numeric columns (we'll use these to compute euclidean distance)\n",
    "distance_columns = ['age', 'g', 'gs', 'mp', 'fg', 'fga', 'fg.', 'x3p', 'x3pa', 'x3p.', 'x2p', 'x2pa', 'x2p.', 'efg.', 'ft', 'fta', 'ft.', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts']\n",
    "\n",
    "#clearing NA values\n",
    "nba = nba_df.dropna()\n",
    "\n",
    "def euclidean_distance(row):\n",
    "    \"\"\"\n",
    "    A simple euclidean distance function\n",
    "    \"\"\"\n",
    "    inner_value = 0\n",
    "    for k in distance_columns:\n",
    "        inner_value += (row[k] - selected_player[k]) ** 2\n",
    "    return math.sqrt(inner_value)\n",
    "\n",
    "# Find the distance from each player in the dataset to lebron.\n",
    "lebron_distance = nba.apply(euclidean_distance, axis=1)\n",
    "\n",
    "# Select only the numeric columns from the NBA dataset\n",
    "nba_numeric = nba[distance_columns]\n",
    "# Normalize all of the numeric columns\n",
    "nba_normalized = (nba_numeric - nba_numeric.mean()) / nba_numeric.std()\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Fill in NA values in nba_normalized\n",
    "nba_normalized.fillna(0, inplace=True)\n",
    "\n",
    "# Find the normalized vector for lebron james.\n",
    "lebron_normalized = nba_normalized[nba[\"player\"] == \"LeBron James\"]\n",
    "\n",
    "# Find the distance between lebron james and everyone else.\n",
    "euclidean_distances = nba_normalized.apply(lambda row: distance.euclidean(row, lebron_normalized), axis=1)\n",
    "\n",
    "# Create a new dataframe with distances.\n",
    "distance_frame = pandas.DataFrame(data={\"dist\": euclidean_distances, \"idx\": euclidean_distances.index})\n",
    "distance_frame.sort_values(by=[\"dist\"], inplace=True)\n",
    "# Find the most similar player to lebron (the lowest distance to lebron is lebron, the second smallest is the most similar non-lebron player)\n",
    "second_smallest = distance_frame.iloc[1][\"idx\"]\n",
    "most_similar_to_lebron = nba.loc[int(second_smallest)][\"player\"]\n",
    "\n",
    "import random\n",
    "from numpy.random import permutation\n",
    "\n",
    "# Randomly shuffle the index of nba.\n",
    "random_indices = permutation(nba.index)\n",
    "\n",
    "# Set a cutoff for how many items we want in the test set (in this case 1/3 of the items)\n",
    "test_cutoff = math.floor(len(nba)/3)\n",
    "\n",
    "# Generate the test set by taking the first 1/3 of the randomly shuffled indices.\n",
    "test = nba.loc[random_indices[1:test_cutoff]]\n",
    "\n",
    "# Generate the train set with the rest of the data.\n",
    "train = nba.loc[random_indices[test_cutoff:]]\n",
    "\n",
    "# The columns that we will be making predictions with.\n",
    "x_columns = ['age', 'g', 'gs', 'mp', 'fg', 'fga', 'fg.', 'x3p', 'x3pa', 'x3p.', 'x2p', 'x2pa', 'x2p.', 'efg.', 'ft', 'fta', 'ft.', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf']\n",
    "# The column that we want to predict.\n",
    "y_column = [\"pts\"]\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# Create the knn model.\n",
    "# Look at the five closest neighbors.\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "# Fit the model on the training data.\n",
    "knn.fit(train[x_columns], train[y_column])\n",
    "# Make point predictions on the test set using the fit model.\n",
    "predictions = knn.predict(test[x_columns])\n",
    "\n",
    "# Get the actual values for the test set.\n",
    "actual = test[y_column]\n",
    "\n",
    "# Compute the mean squared error of our predictions.\n",
    "mse = (((predictions - actual) ** 2).sum()) / len(predictions)\n",
    "\n",
    "#print predicted values\n",
    "predictions_List = [item for sublist in predictions for item in sublist]\n",
    "print('Predicted values (pts): ')\n",
    "print(*predictions_List, sep=\", \")\n",
    "\n",
    "#print actual values\n",
    "actual_List = actual.to_string(header=False,index=False,index_names=False).split(sep='\\n ')\n",
    "actual_print = []\n",
    "for element in actual_List:\n",
    "    actual_print.append(element.strip())\n",
    "\n",
    "print('Actual values (pts): ')\n",
    "print(*actual_print, sep=\", \")\n",
    "\n",
    "#print the mean squared error\n",
    "print('Mean squared error: ', float(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knearest_analysis(data, x_columns, y_column):\n",
    "    import random\n",
    "    from numpy.random import permutation\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    \n",
    "    # Randomly shuffle the index of nba.\n",
    "    random_indices = permutation(data.index)\n",
    "    \n",
    "    # Set a cutoff for how many items we want in the test set (in this case 1/3 of the items)\n",
    "    test_cutoff = math.floor(len(data)/3)\n",
    "    \n",
    "    # Generate the test set by taking the first 1/3 of the randomly shuffled indices.\n",
    "    test = data.loc[random_indices[1:test_cutoff]]\n",
    "    \n",
    "    # Generate the train set with the rest of the data.\n",
    "    train = data.loc[random_indices[test_cutoff:]]\n",
    "    \n",
    "    # Create the knn model.\n",
    "    # Look at the five closest neighbors.\n",
    "    knn = KNeighborsRegressor(n_neighbors=5)\n",
    "    # Fit the model on the training data.\n",
    "    knn.fit(train[x_columns], train[y_column])\n",
    "    # Make point predictions on the test set using the fit model.\n",
    "    predictions = knn.predict(test[x_columns])\n",
    "    # Get the actual values for the test set.\n",
    "    actual = test[y_column]\n",
    "    \n",
    "    # Compute the mean squared error of our predictions.\n",
    "    mse = (((predictions - actual) ** 2).sum()) / len(predictions)\n",
    "    \n",
    "    #print predicted values\n",
    "    predictions_List = [item for sublist in predictions for item in sublist]\n",
    "    print('Predicted values: ')\n",
    "    print(*predictions_List, sep=\", \")\n",
    "    \n",
    "    #print actual values\n",
    "    actual_List = actual.to_string(header=False,index=False,index_names=False).split(sep='\\n ')\n",
    "    actual_print = []\n",
    "    for element in actual_List:\n",
    "        actual_print.append(element.strip())\n",
    "        \n",
    "    print('Actual values: ')\n",
    "    print(*actual_print, sep=\", \")\n",
    "    \n",
    "    #print the mean squared error\n",
    "    print('Mean squared error: ', float(mse))\n",
    "    \n",
    "#get the data\n",
    "with open(\"data/nba_2013.csv\", 'r') as csvfile:\n",
    "    nba = pandas.read_csv(csvfile)\n",
    "# x-values (independent variables)\n",
    "x_columns_test = ['age', 'g', 'gs', 'mp', 'fg', 'fga', 'fg.', 'x3p', 'x3pa', 'x3p.', 'x2p', 'x2pa', 'x2p.', 'efg.', 'ft', 'fta', 'ft.', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf']\n",
    "# y-values (dependent variables)\n",
    "y_column_test = [\"pts\"]\n",
    "\n",
    "knearest_analysis(nba, x_columns_test, y_column_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
