{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Single-Point Test Data\n",
    "\n",
    "## Reading in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(\"FM Radio Signal Strength run 1-5.xlsx\")\n",
    "df2 = pd.read_excel(\"FM Radio Signal Strength run 6-10.xlsx\")\n",
    "df2edit = df2.drop('Frequency', axis=1)\n",
    "\n",
    "df3 = pd.read_excel(\"FM Radio Signal Strength run 11-20.xlsx\")\n",
    "df3edit = df3.drop('Frequency', axis=1)\n",
    "\n",
    "data_frames = [df1, df2edit, df3edit]\n",
    "all_data_unsorted = pd.concat(data_frames, axis=1)\n",
    "test_df_unsorted = all_data_unsorted.copy()\n",
    "test_df_unsorted.fillna(0.0)\n",
    "final_test_df = test_df_unsorted.groupby(test_df_unsorted.Frequency).sum()\n",
    "cols = final_test_df.columns\n",
    "final_test_df[cols] = final_test_df[cols].replace({0.0:np.nan})\n",
    "all_data = final_test_df\n",
    "all_data.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_In_Files_Excel(fileList):\n",
    "    '''Returns a dataframe made by reading in all files \n",
    "    in a list and combines their data together\n",
    "    fileList must be a list of filenames as strings and the files\n",
    "    must share a common first column'''\n",
    "    dfbase = pd.read_excel(fileList[0])\n",
    "    joint_col = dfbase.columns[0]\n",
    "    \n",
    "    if len(fileList) == 1:\n",
    "        return dfbase\n",
    "    else:\n",
    "        df_List = [dfbase]\n",
    "    for i in range(1,len(fileList)):\n",
    "        dfadd = pd.read_excel(fileList[i])\n",
    "        dfadd_edit = dfadd.drop(joint_col, axis=1)\n",
    "        df_List.append(dfadd_edit)\n",
    "        \n",
    "    dfbase_new = pd.concat(df_List, axis=1)\n",
    "    \n",
    "    return dfbase_new\n",
    "\n",
    "#all_data_unsorted = read_In_Files_Excel([\"FM Radio Signal Strength run 1-5.xlsx\", \"FM Radio Signal Strength run 6-10.xlsx\", \"FM Radio Signal Strength run 11-20.xlsx\"])\n",
    "#all_data_unsorted.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(data):\n",
    "    '''Returns a dataframe with all frequency lines\n",
    "    consolidated into one line per frequency with\n",
    "    no repeats, and all data is still present'''\n",
    "    df_unsorted = data.copy()\n",
    "    joint_col = df_unsorted.columns[0]\n",
    "    df_unsorted.fillna(0.0)\n",
    "    df_sorted = data.groupby(df_unsorted[joint_col]).sum()\n",
    "    df_sorted_edit = df_sorted.drop('Frequency', axis=1)\n",
    "    cols = df_sorted_edit.columns\n",
    "    df_sorted_edit[cols] = df_sorted_edit[cols].replace({0.0:np.nan})\n",
    "    return df_sorted_edit\n",
    "\n",
    "#all_data = clean_dataframe(all_data_unsorted)\n",
    "#all_data.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_clean_data(fileList):\n",
    "    '''Reads in all the files entered and cleans\n",
    "    up the data so as many nans as possible are \n",
    "    removed'''\n",
    "    all_data_unsorted = read_In_Files_Excel(fileList)\n",
    "    all_data = clean_dataframe(all_data_unsorted)\n",
    "    return all_data\n",
    "\n",
    "file_List = [\"FM Radio Signal Strength run 1-5.xlsx\", \"FM Radio Signal Strength run 6-10.xlsx\", \"FM Radio Signal Strength run 11-20.xlsx\"]\n",
    "all_data = read_and_clean_data(file_List)\n",
    "all_data.head(26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strongest signal per run\n",
    "strong_List = []\n",
    "df_dim = all_data.shape\n",
    "\n",
    "for i in range(df_dim[1]):\n",
    "    max_signal = 0\n",
    "    max_signal_loc = 0\n",
    "    for j in range(df_dim[0]):\n",
    "        current_signal = all_data.iloc[j,i]\n",
    "        if current_signal > max_signal:\n",
    "            max_signal = current_signal\n",
    "            max_signal_loc = all_data.index[j]\n",
    "    strong_List.append([max_signal_loc, max_signal])\n",
    "    \n",
    "print(strong_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_data.groupby(\"Frequency\")[\"Power\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weakest signal per run\n",
    "weak_List = []\n",
    "df_dim = all_data.shape\n",
    "\n",
    "for i in range(df_dim[1]):\n",
    "    min_signal = 110\n",
    "    min_signal_loc = 0\n",
    "    for j in range(df_dim[0]):\n",
    "        current_signal = all_data.iloc[j,i]\n",
    "        if (current_signal < min_signal) and pd.notna(current_signal):\n",
    "            min_signal = current_signal\n",
    "            min_signal_loc = all_data.index[j]\n",
    "    weak_List.append([min_signal_loc, min_signal])\n",
    "    # potential for multiple signal magnitudes being the same\n",
    "print(weak_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_data.groupby(\"Frequency\")[\"Power\"].min() #add/based on conditions, ex. max for conditions 1-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average signal strength\n",
    "avg_List = []\n",
    "df_dim = all_data.shape\n",
    "\n",
    "for j in range(df_dim[1]):\n",
    "    sum_signal = 0\n",
    "    num_signal = 0\n",
    "    for i in range(df_dim[0]):\n",
    "        if pd.notna(all_data.iloc[i,j]):\n",
    "            sum_signal = sum_signal + all_data.iloc[i,j]\n",
    "            num_signal = num_signal + 1\n",
    "    avg_signal = sum_signal/num_signal\n",
    "    avg_List.append(avg_signal)\n",
    "    \n",
    "print(avg_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_data.groupby(\"Frequency\")[\"Power\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best run per frequency\n",
    "values_df = all_data.copy()\n",
    "freq_max_list = values_df.max(axis=1, skipna=True)\n",
    "row_List = []\n",
    "\n",
    "for i in range(len(all_data)):\n",
    "    row_List.append(all_data.index[i])\n",
    "\n",
    "freqList = []\n",
    "valueList = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    freq_value = freq_max_list[values_df.index[i]]\n",
    "    freq = row_List[i]\n",
    "    if freq in freqList:\n",
    "        former_case = freqList.index(freq)\n",
    "        if freq_value > valueList[former_case]:\n",
    "            valueList.remove(valueList[former_case])\n",
    "            freqList.remove(freq)\n",
    "            valueList.append(freq_value)\n",
    "            freqList.append(freq)\n",
    "    else:\n",
    "        valueList.append(freq_value)\n",
    "        freqList.append(freq)\n",
    "        \n",
    "print(freqList)\n",
    "print(valueList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_strongest_signal(data, run_num):\n",
    "    '''Returns the strongest signal power for the\n",
    "    provided run if the run is in the data and \n",
    "    a notice that the run is not in the data if\n",
    "    applicable'''\n",
    "    strong_signal_List = []\n",
    "    \n",
    "    df_dim = all_data.shape\n",
    "\n",
    "    for i in range(df_dim[1]):\n",
    "        max_signal = 0\n",
    "        for j in range(df_dim[0]):\n",
    "            current_signal = all_data.iloc[j,i]\n",
    "            if current_signal > max_signal:\n",
    "                max_signal = current_signal\n",
    "        strong_signal_List.append(max_signal)\n",
    "    \n",
    "    if run_num > len(strong_signal_List):\n",
    "        return print('This run is not in the data.')\n",
    "    else:\n",
    "        return print('The maximum signal power for this run is:', strong_signal_List[run_num - 1], 'dBm.')\n",
    "\n",
    "run_strongest_signal(all_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_weakest_signal(data, run_num):\n",
    "    '''Returns the weakest signal power for the\n",
    "    provided run if the run is in the data and \n",
    "    a notice that the run is not in the data if\n",
    "    applicable'''\n",
    "    weak_signal_List = []\n",
    "    \n",
    "    df_dim = all_data.shape\n",
    "\n",
    "    for i in range(df_dim[1]):\n",
    "        min_signal = 110\n",
    "        for j in range(df_dim[0]):\n",
    "            current_signal = all_data.iloc[j,i]\n",
    "            if current_signal < min_signal:\n",
    "                min_signal = current_signal\n",
    "        weak_signal_List.append(min_signal)\n",
    "    \n",
    "    if run_num > len(weak_signal_List):\n",
    "        return print('This run is not in the data.')\n",
    "    else:\n",
    "        return print('The minimum signal power for this run is:', weak_signal_List[run_num - 1], 'dBm.')\n",
    "\n",
    "run_weakest_signal(all_data, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_avg_signal(data, run_num):\n",
    "    '''Returns the average signal power for the\n",
    "    provided run if the run is in the data and \n",
    "    a notice that the run is not in the data if\n",
    "    applicable'''\n",
    "    avg_signals = []\n",
    "    df_dim = all_data.shape\n",
    "\n",
    "    for j in range(df_dim[1]):\n",
    "        sum_signal = 0\n",
    "        num_signal = 0\n",
    "        for i in range(df_dim[0]):\n",
    "            if pd.notna(all_data.iloc[i,j]):\n",
    "                sum_signal = sum_signal + all_data.iloc[i,j]\n",
    "                num_signal = num_signal + 1\n",
    "        avg_signal = sum_signal/num_signal\n",
    "        avg_signals.append(avg_signal)\n",
    "        \n",
    "    if run_num > len(avg_signals):\n",
    "        return print('This run is not in the data.')\n",
    "    else:\n",
    "        return print('The average signal power for this run is:', avg_signals[run_num - 1], 'dBm.')\n",
    "    \n",
    "run_avg_signal(all_data, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find maximum signal for the provided frequency in data\n",
    "def max_signal_per_freq(data, frequency):\n",
    "    '''Returns the maximum signal power for the input frequency\n",
    "    if frequency is present and a notice of absence if not'''\n",
    "    values_df = data.copy()\n",
    "    freq_max_list = values_df.max(axis=1, skipna=True)\n",
    "    row_List = []\n",
    "    \n",
    "    for i in range(len(all_data)):\n",
    "        row_List.append(all_data.index[i])\n",
    "    \n",
    "    freqList = []\n",
    "    valueList = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        freq_value = freq_max_list[values_df.index[i]]\n",
    "        freq = row_List[i]\n",
    "        if freq in freqList:\n",
    "            former_case = freqList.index(freq)\n",
    "            if freq_value > valueList[former_case]:\n",
    "                valueList.remove(valueList[former_case])\n",
    "                freqList.remove(freq)\n",
    "                valueList.append(freq_value)\n",
    "                freqList.append(freq)\n",
    "        else:\n",
    "            valueList.append(freq_value)\n",
    "            freqList.append(freq)\n",
    "    if frequency in freqList:\n",
    "        freq_loc = freqList.index(frequency)\n",
    "        return print('The maximum signal power for this frequency is:', valueList[freq_loc], 'dBm.')\n",
    "    else:\n",
    "        return print('This frequency is not in the data.')\n",
    "    \n",
    "max_signal_per_freq(all_data, 107.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_data_max_signal(data, frequency):\n",
    "    values_df = data.copy()\n",
    "    maxs = values_df.groupby(\"Frequency\")[\"Power\"].max()\n",
    "    if frequency in maxs:\n",
    "        return print('The maximum signal power for this frequency is:', maxs[frequency], 'dBm.')\n",
    "    else:\n",
    "        return print('This frequency is not in the data.')\n",
    "    \n",
    "line_data_max_signal(line_data, 99.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_data_min_signal(data, frequency):\n",
    "    values_df = data.copy()\n",
    "    mins = values_df.groupby(\"Frequency\")[\"Power\"].min()\n",
    "    if frequency in mins:\n",
    "        return print('The minimum signal power for this frequency is:', mins[frequency], 'dBm.')\n",
    "    else:\n",
    "        return print('This frequency is not in the data.')\n",
    "    \n",
    "line_data_min_signal(line_data, 99.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_data_mean_signal(data, frequency):\n",
    "    values_df = data.copy()\n",
    "    means = values_df.groupby(\"Frequency\")[\"Power\"].mean()\n",
    "    if frequency in means:\n",
    "        return print('The mean signal power for this frequency is:', means[frequency], 'dBm.')\n",
    "    else:\n",
    "        return print('This frequency is not in the data.')\n",
    "    \n",
    "line_data_mean_signal(line_data, 99.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code put data in a form for graphing without gaps in it\n",
    "def plotData(data):\n",
    "    '''Returns the input dataframe with columns \n",
    "    indicating which cells to use to graph in order \n",
    "    to account for the nans present'''\n",
    "    plot_data = data.copy()\n",
    "    \n",
    "    run1use = np.isfinite(all_data['Run 1'])\n",
    "    plot_data.insert(20, \"run1use\", run1use)\n",
    "    \n",
    "    run2use = np.isfinite(all_data['Run 2'])\n",
    "    plot_data.insert(21, \"run2use\", run2use)\n",
    "    \n",
    "    run3use = np.isfinite(all_data['Run 3'])\n",
    "    plot_data.insert(22, \"run3use\", run3use)\n",
    "    \n",
    "    run4use = np.isfinite(all_data['Run 4'])\n",
    "    plot_data.insert(23, \"run4use\", run4use)\n",
    "    \n",
    "    run5use = np.isfinite(all_data['Run 5'])\n",
    "    plot_data.insert(24, \"run5use\", run5use)\n",
    "    \n",
    "    run6use = np.isfinite(all_data['Run 6'])\n",
    "    plot_data.insert(25, \"run6use\", run6use)\n",
    "    \n",
    "    run7use = np.isfinite(all_data['Run 7'])\n",
    "    plot_data.insert(26, \"run7use\", run7use)\n",
    "    \n",
    "    run8use = np.isfinite(all_data[' Run 8'])\n",
    "    plot_data.insert(27, \"run8use\", run8use)\n",
    "    \n",
    "    run9use = np.isfinite(all_data['Run 9'])\n",
    "    plot_data.insert(28, \"run9use\", run9use)\n",
    "    \n",
    "    run10use = np.isfinite(all_data['Run 10'])\n",
    "    plot_data.insert(29, \"run10use\", run10use)\n",
    "    \n",
    "    run11use = np.isfinite(all_data['Run 11'])\n",
    "    plot_data.insert(30, \"run11use\", run11use)\n",
    "    \n",
    "    run12use = np.isfinite(all_data['Run 12'])\n",
    "    plot_data.insert(31, \"run12use\", run12use)\n",
    "    \n",
    "    run13use = np.isfinite(all_data['Run 13'])\n",
    "    plot_data.insert(32, \"run13use\", run13use)\n",
    "    \n",
    "    run14use = np.isfinite(all_data['Run 14'])\n",
    "    plot_data.insert(33, \"run14use\", run14use)\n",
    "    \n",
    "    run15use = np.isfinite(all_data['Run 15'])\n",
    "    plot_data.insert(34, \"run15use\", run15use)\n",
    "    \n",
    "    run16use = np.isfinite(all_data['Run 16'])\n",
    "    plot_data.insert(35, \"run16use\", run16use)\n",
    "    \n",
    "    run17use = np.isfinite(all_data['Run 17'])\n",
    "    plot_data.insert(36, \"run17use\", run17use)\n",
    "    \n",
    "    run18use = np.isfinite(all_data['Run 18'])\n",
    "    plot_data.insert(37, \"run18use\", run18use)\n",
    "    \n",
    "    run19use = np.isfinite(all_data['Run 19'])\n",
    "    plot_data.insert(38, \"run19use\", run19use)\n",
    "    \n",
    "    run20use = np.isfinite(all_data['Run 20'])\n",
    "    plot_data.insert(39, \"run20use\", run20use)\n",
    "    \n",
    "    return plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist 5 miles, 10% humidity plot\n",
    "\n",
    "def plot_runs_1to5(data):\n",
    "    '''Plots the first data set of the dataframe'''\n",
    "    fig, ax = plt.subplots()\n",
    "    run_List = ['Run 1', 'Run 2', 'Run 3', 'Run 4', 'Run 5']\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    plot_data = plotData(data)\n",
    "    ax.scatter(data.index[plot_data.run1use],plot_data['Run 1'][plot_data.run1use])\n",
    "    ax.scatter(data.index[plot_data.run2use],plot_data['Run 2'][plot_data.run2use])\n",
    "    ax.scatter(data.index[plot_data.run3use],plot_data['Run 3'][plot_data.run3use])\n",
    "    ax.scatter(data.index[plot_data.run4use],plot_data['Run 4'][plot_data.run4use])\n",
    "    ax.scatter(data.index[plot_data.run5use],plot_data['Run 5'][plot_data.run5use])\n",
    "    ax.set_xlabel('Frequency (kHz)')\n",
    "    ax.set_ylabel('Signal Strength (dBm)')\n",
    "    fig.suptitle('Frequency vs Signal Strength (10% Humidity, 5 miles)')\n",
    "    plt.legend(run_List)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_runs_1to5(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist 10 miles, 10% humidity plot\n",
    "\n",
    "def plot_runs_6to10(data):\n",
    "    '''Plots the second data set of the dataframe'''\n",
    "    fig, ax = plt.subplots()\n",
    "    run_List = ['Run 6', 'Run 7', 'Run 8', 'Run 9', 'Run 10']\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    plot_data = plotData(data)\n",
    "    ax.scatter(data.index[plot_data.run6use],plot_data['Run 6'][plot_data.run6use])\n",
    "    ax.scatter(data.index[plot_data.run7use],plot_data['Run 7'][plot_data.run7use])\n",
    "    ax.scatter(data.index[plot_data.run8use],plot_data[' Run 8'][plot_data.run8use])\n",
    "    ax.scatter(data.index[plot_data.run9use],plot_data['Run 9'][plot_data.run9use])\n",
    "    ax.scatter(data.index[plot_data.run10use],plot_data['Run 10'][plot_data.run10use])\n",
    "    ax.set_xlabel('Frequency (kHz)')\n",
    "    ax.set_ylabel('Signal Strength (dBm)')\n",
    "    fig.suptitle('Frequency vs Signal Strength (10% Humidity, 10 miles)')\n",
    "    plt.legend(run_List)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#plot_runs_6to10(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist 5 miles, 90% humidity plot\n",
    "\n",
    "def plot_runs_11to15(data):\n",
    "    '''Plots the third data set of the dataframe'''\n",
    "    fig, ax = plt.subplots()\n",
    "    run_List = ['Run 11', 'Run 12', 'Run 13', 'Run 14', 'Run 15']\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    plot_data = plotData(data)\n",
    "    ax.scatter(data.index[plot_data.run11use],plot_data['Run 11'][plot_data.run11use])\n",
    "    ax.scatter(data.index[plot_data.run12use],plot_data['Run 12'][plot_data.run12use])\n",
    "    ax.scatter(data.index[plot_data.run13use],plot_data['Run 13'][plot_data.run13use])\n",
    "    ax.scatter(data.index[plot_data.run14use],plot_data['Run 14'][plot_data.run14use])\n",
    "    ax.scatter(data.index[plot_data.run15use],plot_data['Run 15'][plot_data.run15use])\n",
    "    ax.set_xlabel('Frequency (kHz)')\n",
    "    ax.set_ylabel('Signal Strength (dBm)')\n",
    "    fig.suptitle('Frequency vs Signal Strength (90% Humidity, 5 miles)')\n",
    "    plt.legend(run_List)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#plot_runs_11to15(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist 10 miles, 90% humidity plot\n",
    "\n",
    "def plot_runs_16to20(data):\n",
    "    '''Plots the fourth data set of the dataframe'''\n",
    "    fig, ax = plt.subplots()\n",
    "    run_List = ['Run 16', 'Run 17', 'Run 18', 'Run 19', 'Run 20']\n",
    "    runs_List = ['run16use', 'run17use', 'run18use', 'run19use', 'run20use']\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    plot_data = plotData(data)\n",
    "    ax.scatter(data.index[plot_data[runs_List[0]]],plot_data['Run 16'][plot_data[runs_List[0]]])\n",
    "    ax.scatter(data.index[plot_data[runs_List[1]]],plot_data['Run 17'][plot_data[runs_List[1]]])\n",
    "    ax.scatter(data.index[plot_data[runs_List[2]]],plot_data['Run 18'][plot_data[runs_List[2]]])\n",
    "    ax.scatter(data.index[plot_data[runs_List[3]]],plot_data['Run 19'][plot_data[runs_List[3]]])\n",
    "    ax.scatter(data.index[plot_data[runs_List[4]]],plot_data['Run 20'][plot_data[runs_List[4]]])\n",
    "    ax.set_xlabel('Frequency (kHz)')\n",
    "    ax.set_ylabel('Signal Strength (dBm)')\n",
    "    fig.suptitle('Frequency vs Signal Strength (90% Humidity, 10 miles)')\n",
    "    plt.legend(run_List)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#plot_runs_16to20(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_groups(data):\n",
    "    '''Plots all the data on graphs by the \n",
    "    set the data is a part of'''\n",
    "    plot_runs_1to5(data)\n",
    "    plot_runs_6to10(data)\n",
    "    plot_runs_11to15(data)\n",
    "    plot_runs_16to20(data)\n",
    "    \n",
    "plot_by_groups(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_runs_1to20(data):\n",
    "    '''Plots all the data on one graph'''\n",
    "    fig, ax = plt.subplots()\n",
    "    run_List = ['Run 1', 'Run 2', 'Run 3', 'Run 4', 'Run 5', 'Run 6', 'Run 7', \n",
    "                'Run 8', 'Run 9', 'Run 10', 'Run 11', 'Run 12', 'Run 13', 'Run 14', \n",
    "                'Run 15', 'Run 16', 'Run 17', 'Run 18', 'Run 19', 'Run 20']\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    plot_data = plotData(data)\n",
    "    ax.scatter(data.index[plot_data.run1use],plot_data['Run 1'][plot_data.run1use], color='b')\n",
    "    ax.scatter(data.index[plot_data.run2use],plot_data['Run 2'][plot_data.run2use], color='b')\n",
    "    ax.scatter(data.index[plot_data.run3use],plot_data['Run 3'][plot_data.run3use], color='b')\n",
    "    ax.scatter(data.index[plot_data.run4use],plot_data['Run 4'][plot_data.run4use], color='b')\n",
    "    ax.scatter(data.index[plot_data.run5use],plot_data['Run 5'][plot_data.run5use], color='b')\n",
    "    ax.scatter(data.index[plot_data.run6use],plot_data['Run 6'][plot_data.run6use], color='g')\n",
    "    ax.scatter(data.index[plot_data.run7use],plot_data['Run 7'][plot_data.run7use], color='g')\n",
    "    ax.scatter(data.index[plot_data.run8use],plot_data[' Run 8'][plot_data.run8use], color='g')\n",
    "    ax.scatter(data.index[plot_data.run9use],plot_data['Run 9'][plot_data.run9use], color='g')\n",
    "    ax.scatter(data.index[plot_data.run10use],plot_data['Run 10'][plot_data.run10use], color='g')\n",
    "    ax.scatter(data.index[plot_data.run11use],plot_data['Run 11'][plot_data.run11use], color='r')\n",
    "    ax.scatter(data.index[plot_data.run12use],plot_data['Run 12'][plot_data.run12use], color='r')\n",
    "    ax.scatter(data.index[plot_data.run13use],plot_data['Run 13'][plot_data.run13use], color='r')\n",
    "    ax.scatter(data.index[plot_data.run14use],plot_data['Run 14'][plot_data.run14use], color='r')\n",
    "    ax.scatter(data.index[plot_data.run15use],plot_data['Run 15'][plot_data.run15use], color='r')\n",
    "    ax.scatter(data.index[plot_data.run16use],plot_data['Run 16'][plot_data.run16use], color='c')\n",
    "    ax.scatter(data.index[plot_data.run17use],plot_data['Run 17'][plot_data.run17use], color='c')\n",
    "    ax.scatter(data.index[plot_data.run18use],plot_data['Run 18'][plot_data.run18use], color='c')\n",
    "    ax.scatter(data.index[plot_data.run19use],plot_data['Run 19'][plot_data.run19use], color='c')\n",
    "    ax.scatter(data.index[plot_data.run20use],plot_data['Run 20'][plot_data.run20use], color='c')\n",
    "    ax.set_xlabel('Frequency (kHz)')\n",
    "    ax.set_ylabel('Signal Strength (dBm)')\n",
    "    fig.suptitle('Frequency vs Signal Strength (All Runs)')\n",
    "    plt.legend(run_List, ncol=4)\n",
    "    plt.show()\n",
    "\n",
    "# dashes and dots\n",
    "plot_runs_1to20(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first run of each set of five\n",
    "def plot_first_runs(data):\n",
    "    fig, ax = plt.subplots()\n",
    "    run_List = ['Run 1', 'Run 6', 'Run 11', 'Run 16']\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    plot_data = plotData(data)\n",
    "    ax.scatter(data.index[plot_data.run1use],plot_data['Run 1'][plot_data.run1use], color='b')\n",
    "    ax.scatter(data.index[plot_data.run6use],plot_data['Run 6'][plot_data.run6use], color='g')\n",
    "    ax.scatter(data.index[plot_data.run11use],plot_data['Run 11'][plot_data.run11use], color='r')\n",
    "    ax.scatter(data.index[plot_data.run16use],plot_data['Run 16'][plot_data.run16use], color='m')\n",
    "    ax.set_xlabel('Frequency (kHz)')\n",
    "    ax.set_ylabel('Signal Strength (dBm)')\n",
    "    fig.suptitle('Frequency vs Signal Strength (Runs 1, 6, 11, and 16)')\n",
    "    plt.legend(run_List, ncol=4)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_first_runs(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the second run of each set of five\n",
    "def plot_second_runs(data):\n",
    "    fig, ax = plt.subplots()\n",
    "    run_List = ['Run 2', 'Run 7', 'Run 12', 'Run 17']\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    plot_data = plotData(data)\n",
    "    ax.scatter(data.index[plot_data.run2use],plot_data['Run 2'][plot_data.run2use], color='b')\n",
    "    ax.scatter(data.index[plot_data.run7use],plot_data['Run 7'][plot_data.run7use], color='g')\n",
    "    ax.scatter(data.index[plot_data.run12use],plot_data['Run 12'][plot_data.run12use], color='r')\n",
    "    ax.scatter(data.index[plot_data.run17use],plot_data['Run 17'][plot_data.run17use], color='m')\n",
    "    ax.set_xlabel('Frequency (kHz)')\n",
    "    ax.set_ylabel('Signal Strength (dBm)')\n",
    "    fig.suptitle('Frequency vs Signal Strength (Runs 2, 7, 12, and 17)')\n",
    "    plt.legend(run_List, ncol=4)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_second_runs(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the third run of each set of five\n",
    "def plot_third_runs(data):\n",
    "    fig, ax = plt.subplots()\n",
    "    run_List = ['Run 3', 'Run 8', 'Run 13', 'Run 18']\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    plot_data = plotData(data)\n",
    "    ax.scatter(data.index[plot_data.run3use],plot_data['Run 3'][plot_data.run3use], color='b')\n",
    "    ax.scatter(data.index[plot_data.run8use],plot_data[' Run 8'][plot_data.run8use], color='g')\n",
    "    ax.scatter(data.index[plot_data.run13use],plot_data['Run 13'][plot_data.run13use], color='r')\n",
    "    ax.scatter(data.index[plot_data.run18use],plot_data['Run 18'][plot_data.run18use], color='m')\n",
    "    ax.set_xlabel('Frequency (kHz)')\n",
    "    ax.set_ylabel('Signal Strength (dBm)')\n",
    "    fig.suptitle('Frequency vs Signal Strength (Runs 3, 8, 13, and 18)')\n",
    "    plt.legend(run_List, ncol=4)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_third_runs(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the fourth run of each set of five\n",
    "def plot_fourth_runs(data):\n",
    "    fig, ax = plt.subplots()\n",
    "    run_List = ['Run 4', 'Run 9', 'Run 14', 'Run 19']\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    plot_data = plotData(data)\n",
    "    ax.scatter(data.index[plot_data.run4use],plot_data['Run 4'][plot_data.run4use], color='b')\n",
    "    ax.scatter(data.index[plot_data.run9use],plot_data['Run 9'][plot_data.run9use], color='g')\n",
    "    ax.scatter(data.index[plot_data.run14use],plot_data['Run 14'][plot_data.run14use], color='r')\n",
    "    ax.scatter(data.index[plot_data.run19use],plot_data['Run 19'][plot_data.run19use], color='m')\n",
    "    ax.set_xlabel('Frequency (kHz)')\n",
    "    ax.set_ylabel('Signal Strength (dBm)')\n",
    "    fig.suptitle('Frequency vs Signal Strength (Runs 4, 9, 14, and 19)')\n",
    "    plt.legend(run_List, ncol=4)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_fourth_runs(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the fifth run of each set of five\n",
    "def plot_fifth_runs(data):\n",
    "    fig, ax = plt.subplots()\n",
    "    run_List = ['Run 5', 'Run 10', 'Run 15', 'Run 20']\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    plot_data = plotData(data)\n",
    "    ax.scatter(data.index[plot_data.run5use],plot_data['Run 5'][plot_data.run5use], color='b')\n",
    "    ax.scatter(data.index[plot_data.run10use],plot_data['Run 10'][plot_data.run10use], color='g')\n",
    "    ax.scatter(data.index[plot_data.run15use],plot_data['Run 15'][plot_data.run15use], color='r')\n",
    "    ax.scatter(data.index[plot_data.run20use],plot_data['Run 20'][plot_data.run20use], color='m')\n",
    "    ax.set_xlabel('Frequency (kHz)')\n",
    "    ax.set_ylabel('Signal Strength (dBm)')\n",
    "    fig.suptitle('Frequency vs Signal Strength (Runs 5, 10, 15, and 20)')\n",
    "    plt.legend(run_List, ncol=4)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_fifth_runs(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot using line data\n",
    "def determine_color_4groups(data, list_groups):\n",
    "    # ex. list_groups = [[5, 10], [10, 10], [5,90], [10,90]]\n",
    "    color_List = []\n",
    "    for i in range(len(data.Frequency)):\n",
    "        if (data.Distance[i] == list_groups[0][0]) and (data.Humidity[i] == list_groups[0][1]):\n",
    "            color_List.append('b')\n",
    "        elif (data.Distance[i] == list_groups[1][0]) and (data.Humidity[i] == list_groups[1][1]):\n",
    "            color_List.append('g')\n",
    "        elif (data.Distance[i] == list_groups[2][0]) and (data.Humidity[i] == list_groups[2][1]):\n",
    "            color_List.append('r')\n",
    "        elif (data.Distance[i] == list_groups[3][0]) and (data.Humidity[i] == list_groups[3][1]):\n",
    "            color_List.append('y')\n",
    "    \n",
    "    return color_List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def line_data_scatter(data, groups_List, runList, run_Color):\n",
    "    plot_data = data.copy()\n",
    "    legendList = []\n",
    "    for i in range(len(runList)):\n",
    "        legendList.append(mpatches.Patch(color=run_Color[i], label=runList[i]))\n",
    "    \n",
    "    color_List = determine_color_4groups(plot_data, groups_List)\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    ax.scatter(plot_data.Frequency, plot_data.Power, color=color_List)\n",
    "    ax.set_xlabel('Frequency (kHz)')\n",
    "    ax.set_ylabel('Signal Strength (dBm)')\n",
    "    fig.suptitle('Frequency vs Signal Strength (All Runs)')\n",
    "    plt.legend(handles=legendList)\n",
    "    plt.show()\n",
    "    \n",
    "test_List = [[5, 10], [10, 10], [5,90], [10,90]]\n",
    "run_List = ['Run 1-5', 'Run 6-10', 'Run 11-15', 'Run 16-20']\n",
    "run_color = ['b', 'g', 'r', 'y']\n",
    "line_data_scatter(line_data, test_List, run_List, run_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction plots\n",
    "# distributions\n",
    "# histogram colors based on which run of the group it is\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "data = all_data.copy()\n",
    "run_List = ['Run 1', 'Run 2', 'Run 3', 'Run 4', 'Run 5', 'Run 6', 'Run 7', \n",
    "            'Run 8', 'Run 9', 'Run 10', 'Run 11', 'Run 12', 'Run 13', 'Run 14', \n",
    "            'Run 15', 'Run 16', 'Run 17', 'Run 18', 'Run 19', 'Run 20']\n",
    "color_List = ['b', 'g', 'r', 'c', 'y']*4\n",
    "ax.hist([data['Run 1'], data['Run 2'], data['Run 3'], data['Run 4'], \n",
    "          data['Run 5'], data['Run 6'], data['Run 7'], data[' Run 8'], \n",
    "          data['Run 9'], data['Run 10'], data['Run 11'], data['Run 12'], \n",
    "          data['Run 13'], data['Run 14'], data['Run 15'], data['Run 16'], \n",
    "          data['Run 17'], data['Run 18'], data['Run 19'], data['Run 20']], \n",
    "          bins='auto', color= color_List)\n",
    "ax.set_xlabel('Signal Power')\n",
    "ax.set_ylabel('Number of Occurrences')\n",
    "fig.suptitle('Signal Power Histogram')\n",
    "plt.legend(run_List, ncol=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram colors based on conditions during run\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "data = all_data.copy()\n",
    "run_List = ['Run 1', 'Run 2', 'Run 3', 'Run 4', 'Run 5', 'Run 6', 'Run 7', \n",
    "            'Run 8', 'Run 9', 'Run 10', 'Run 11', 'Run 12', 'Run 13', 'Run 14', \n",
    "            'Run 15', 'Run 16', 'Run 17', 'Run 18', 'Run 19', 'Run 20']\n",
    "color_List = ['b', 'b', 'b', 'b', 'b', 'g', 'g', 'g', 'g', 'g', \n",
    "              'r', 'r', 'r', 'r', 'r', 'c', 'c', 'c', 'c', 'c']\n",
    "ax.hist([data['Run 1'], data['Run 2'], data['Run 3'], data['Run 4'], \n",
    "          data['Run 5'], data['Run 6'], data['Run 7'], data[' Run 8'], \n",
    "          data['Run 9'], data['Run 10'], data['Run 11'], data['Run 12'], \n",
    "          data['Run 13'], data['Run 14'], data['Run 15'], data['Run 16'], \n",
    "          data['Run 17'], data['Run 18'], data['Run 19'], data['Run 20']], \n",
    "          bins='auto', color= color_List)\n",
    "ax.set_xlabel('Signal Power')\n",
    "ax.set_ylabel('Number of Occurrences')\n",
    "fig.suptitle('Signal Power Histogram')\n",
    "plt.legend(run_List, ncol=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_Plot(data):\n",
    "    '''Plots a histogram from the data given, with\n",
    "    colors dependent on which set of data it is from'''\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    hist_data = data.copy()\n",
    "    \n",
    "    run_List = hist_data.columns\n",
    "    \n",
    "    color_List = ['b', 'b', 'b', 'b', 'b', 'g', 'g', 'g', 'g', 'g', \n",
    "                  'r', 'r', 'r', 'r', 'r', 'c', 'c', 'c', 'c', 'c']\n",
    "    \n",
    "    ax.hist([data['Run 1'], data['Run 2'], data['Run 3'], data['Run 4'], \n",
    "             data['Run 5'], data['Run 6'], data['Run 7'], data[' Run 8'], \n",
    "             data['Run 9'], data['Run 10'], data['Run 11'], data['Run 12'], \n",
    "             data['Run 13'], data['Run 14'], data['Run 15'], data['Run 16'], \n",
    "             data['Run 17'], data['Run 18'], data['Run 19'], data['Run 20']], \n",
    "            bins='auto', color= color_List)\n",
    "    ax.set_xlabel('Signal Power (dBm)')\n",
    "    ax.set_ylabel('Number of Occurrences')\n",
    "    fig.suptitle('Signal Power Histogram')\n",
    "    plt.legend(run_List, ncol=4)\n",
    "    plt.show()\n",
    "histogram_Plot(all_data)\n",
    "print(all_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_points(data, run_name):\n",
    "    run_use = np.isfinite(all_data[run_name])\n",
    "    \n",
    "    return run_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_points_groupby(data, run_name):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_runs_var(data, runList, colorList):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    \n",
    "    for i in range(len(runList)):\n",
    "        plot_data = data.copy()\n",
    "        run_use = valid_points(all_data, runList[i])\n",
    "        plot_data.insert(1, \"run_use\", run_use)\n",
    "        ax.scatter(plot_data.index[plot_data.run_use],plot_data[runList[i]][plot_data.run_use], color=colorList[i])\n",
    "        \n",
    "    ax.set_xlabel('Frequency (kHz)')\n",
    "    ax.set_ylabel('Signal Strength (dBm)')\n",
    "    fig.suptitle('Frequency vs Signal Strength')\n",
    "    plt.legend(runList)\n",
    "    plt.show()\n",
    "\n",
    "run_List = ['Run 11', 'Run 5', 'Run 18', 'Run 2', 'Run 7']\n",
    "color_List = ['b', 'r', 'g', 'c', 'm']\n",
    "\n",
    "plot_runs_var(all_data, run_List, color_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_Plot_var(data, groupList):\n",
    "    '''Plots a histogram from the data given, with\n",
    "    colors dependent on which set of data it is from, \n",
    "    currently only works for groups of 5'''\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    hist_data = data.copy()\n",
    "    \n",
    "    run_List = hist_data.columns\n",
    "    \n",
    "    color_List = ['b', 'b', 'b', 'b', 'b', 'g', 'g', 'g', 'g', 'g', \n",
    "                  'r', 'r', 'r', 'r', 'r', 'c', 'c', 'c', 'c', 'c']\n",
    "    \n",
    "\n",
    "    for i in groupList:\n",
    "        ax.hist([hist_data[run_List[i-1]], hist_data[run_List[i]], hist_data[run_List[i+1]],\n",
    "                 hist_data[run_List[i+2]], hist_data[run_List[i+3]]], bins=90, color=color_List[i-1:i+4])\n",
    "    \n",
    "    ax.set_xlabel('Signal Power (dBm)')\n",
    "    ax.set_ylabel('Number of Occurrences')\n",
    "    fig.suptitle('Signal Power Histogram')\n",
    "    plt.legend(run_List, ncol=4)\n",
    "    plt.show()\n",
    "    \n",
    "group_List = [1, 6, 11, 16]\n",
    "histogram_Plot_var(all_data, group_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_histogram_Plot_var(data, groupList, run_cond):\n",
    "    '''Plots a histogram from the data given, with\n",
    "    colors dependent on which set of data it is from, \n",
    "    currently only works for groups of 5'''\n",
    "    \n",
    "    hist_data = data.copy()\n",
    "    \n",
    "    run_List = hist_data.columns\n",
    "    \n",
    "    color_List = ['b', 'b', 'b', 'b', 'b', 'g', 'g', 'g', 'g', 'g', \n",
    "                  'r', 'r', 'r', 'r', 'r', 'c', 'c', 'c', 'c', 'c']\n",
    "    \n",
    "    run_count = 0\n",
    "    for i in groupList:\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(18.5, 10.5)\n",
    "        ax.hist([hist_data[run_List[i-1]], hist_data[run_List[i]], hist_data[run_List[i+1]],\n",
    "                 hist_data[run_List[i+2]], hist_data[run_List[i+3]]], bins='auto', color=color_List[i-1:i+4])\n",
    "        ax.set_xlabel('Signal Power (dBm)')\n",
    "        ax.set_ylabel('Number of Occurrences')\n",
    "        fig.suptitle('Signal Power Histogram: ' + run_cond[run_count])\n",
    "        plt.legend(run_List[i-1:i+4])\n",
    "        plt.show()\n",
    "        run_count = run_count + 1\n",
    "    \n",
    "group_List = [1, 6, 11, 16]\n",
    "runCond = ['5 Miles, 10% Humidity', '10 Miles, 10% Humidity', '5 Miles, 90% Humidity', '10 Miles, 90% Humidity']\n",
    "multiple_histogram_Plot_var(all_data, group_List, runCond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "data = all_data.copy()\n",
    "run_List = data.columns\n",
    "\n",
    "color_List = ['b', 'b', 'b', 'b', 'b', 'g', 'g', 'g', 'g', 'g', \n",
    "              'r', 'r', 'r', 'r', 'r', 'c', 'c', 'c', 'c', 'c']\n",
    "ax.hist([data[run_List]], bins='auto')  #, color= color_List)\n",
    "ax.set_xlabel('Signal Power')\n",
    "ax.set_ylabel('Number of Occurrences')\n",
    "fig.suptitle('Signal Power Histogram')\n",
    "#plt.legend(run_List, ncol=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_List = all_data.sum()\n",
    "count_List = all_data.count()\n",
    "\n",
    "mean_group_1 = (sum_List[0] + sum_List[1] + sum_List[2] + sum_List[3] + sum_List[4])/(count_List[0] + count_List[1] + count_List[2] + count_List[3] + count_List[4])\n",
    "mean_group_2 = (sum_List[5] + sum_List[6] + sum_List[7] + sum_List[8] + sum_List[9])/(count_List[5] + count_List[6] + count_List[7] + count_List[8] + count_List[9])\n",
    "mean_group_3 = (sum_List[10] + sum_List[11] + sum_List[12] + sum_List[13] + sum_List[14])/(count_List[10] + count_List[11] + count_List[12] + count_List[13] + count_List[14])\n",
    "mean_group_4 = (sum_List[15] + sum_List[16] + sum_List[17] + sum_List[18] + sum_List[19])/(count_List[15] + count_List[16] + count_List[17] + count_List[18] + count_List[19])\n",
    "\n",
    "xvalues = [0.0,1.0]\n",
    "line1y = [mean_group_1, mean_group_2]\n",
    "line2y = [mean_group_3, mean_group_4]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(xvalues, line1y, label='10% Humidity')\n",
    "ax.plot(xvalues, line2y, label='90% Humidity')\n",
    "ax.set_xticks((0, 1.))\n",
    "ax.set_xticklabels(('Near', 'Far'))\n",
    "ax.set_xbound((-.2, 1.2))\n",
    "ax.set_xlabel(\"Distance\")\n",
    "ax.legend()\n",
    "plt.ylabel('Mean Signal Strength')\n",
    "plt.title('Signal Power Interaction Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalues = [0.0,1.0]\n",
    "line1y = [mean_group_1, mean_group_3]\n",
    "line2y = [mean_group_2, mean_group_4]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(xvalues, line1y, label='5 Miles')\n",
    "ax.plot(xvalues, line2y, label='10 Miles')\n",
    "ax.set_xticks((0, 1.))\n",
    "ax.set_xticklabels(('Low', 'High'))\n",
    "ax.set_xbound((-.2, 1.2))\n",
    "ax.set_xlabel(\"Humidity\")\n",
    "ax.legend()\n",
    "plt.ylabel('Mean Signal Strength')\n",
    "plt.title('Signal Power Interaction Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interaction_Plots(data):\n",
    "    '''Makes interaction plots of humidity and distance'''\n",
    "    sum_List = data.sum()\n",
    "    count_List = data.count()\n",
    "    \n",
    "    mean_group_1 = (sum_List[0] + sum_List[1] + sum_List[2] + sum_List[3] + sum_List[4])/(count_List[0] + count_List[1] + count_List[2] + count_List[3] + count_List[4])\n",
    "    mean_group_2 = (sum_List[5] + sum_List[6] + sum_List[7] + sum_List[8] + sum_List[9])/(count_List[5] + count_List[6] + count_List[7] + count_List[8] + count_List[9])\n",
    "    mean_group_3 = (sum_List[10] + sum_List[11] + sum_List[12] + sum_List[13] + sum_List[14])/(count_List[10] + count_List[11] + count_List[12] + count_List[13] + count_List[14])\n",
    "    mean_group_4 = (sum_List[15] + sum_List[16] + sum_List[17] + sum_List[18] + sum_List[19])/(count_List[15] + count_List[16] + count_List[17] + count_List[18] + count_List[19])\n",
    "    \n",
    "    xvalues = [0.0,1.0]\n",
    "    line1y = [mean_group_1, mean_group_2]\n",
    "    line2y = [mean_group_3, mean_group_4]\n",
    "    line3y = [mean_group_1, mean_group_3]\n",
    "    line4y = [mean_group_2, mean_group_4]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(xvalues, line1y, label='10% Humidity')\n",
    "    ax.plot(xvalues, line2y, label='90% Humidity')\n",
    "    ax.set_xticks((0, 1.))\n",
    "    ax.set_xticklabels(('Near', 'Far'))\n",
    "    ax.set_xbound((-.2, 1.2))\n",
    "    ax.set_xlabel(\"Distance\")\n",
    "    ax.legend()\n",
    "    plt.ylabel('Mean Signal Strength')\n",
    "    plt.title('Signal Power Interaction Plot')\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(xvalues, line3y, label='5 Miles')\n",
    "    ax.plot(xvalues, line4y, label='10 Miles')\n",
    "    ax.set_xticks((0, 1.))\n",
    "    ax.set_xticklabels(('Low', 'High'))\n",
    "    ax.set_xbound((-.2, 1.2))\n",
    "    ax.set_xlabel(\"Humidity\")\n",
    "    ax.legend()\n",
    "    plt.ylabel('Mean Signal Strength')\n",
    "    plt.title('Signal Power Interaction Plot')\n",
    "    plt.show()\n",
    "    \n",
    "interaction_Plots(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interaction_Plots_var(data, groupLists, labelList):\n",
    "    '''Makes interaction plots of the groups of data, requires a list of 4 lists to work'''\n",
    "    sum_List = data.sum()\n",
    "    count_List = data.count()\n",
    "    mean_List = []\n",
    "    \n",
    "    for i in range(len(groupLists)):\n",
    "        sum_val = 0\n",
    "        count_val = 0\n",
    "        for j in range(len(groupLists[i])):\n",
    "            sum_val = sum_val + sum_List[groupLists[i][j]-1]\n",
    "            count_val = count_val + count_List[groupLists[i][j]-1]\n",
    "        average_val = sum_val/count_val\n",
    "        mean_List.append(average_val)\n",
    "    \n",
    "    # mean_List should have 4 values in it at this point\n",
    "    xvalues = [0.0,1.0]\n",
    "    line1y = [mean_List[0], mean_List[1]]\n",
    "    line2y = [mean_List[2], mean_List[3]]\n",
    "    line3y = [mean_List[0], mean_List[2]]\n",
    "    line4y = [mean_List[1], mean_List[3]]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(xvalues, line1y, label=labelList[2])\n",
    "    ax.plot(xvalues, line2y, label=labelList[3])\n",
    "    ax.set_xticks((0, 1.))\n",
    "    ax.set_xticklabels((labelList[4], labelList[5]))\n",
    "    ax.set_xbound((-.2, 1.2))\n",
    "    ax.set_xlabel(labelList[0])\n",
    "    ax.legend()\n",
    "    plt.ylabel(labelList[1])\n",
    "    plt.title(labelList[6])\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(xvalues, line3y, label=labelList[8])\n",
    "    ax.plot(xvalues, line4y, label=labelList[9])\n",
    "    ax.set_xticks((0, 1.))\n",
    "    ax.set_xticklabels((labelList[10], labelList[11]))\n",
    "    ax.set_xbound((-.2, 1.2))\n",
    "    ax.set_xlabel(labelList[7])\n",
    "    ax.legend()\n",
    "    plt.ylabel(labelList[1])\n",
    "    plt.title(labelList[6])\n",
    "    plt.show()\n",
    "\n",
    "group_List = [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15], [16, 17, 18, 19, 20]]\n",
    "label_List = ['Distance', 'Mean Signal Strength', '10% Humidity', '90% Humidity', 'Near', 'Far', 'Signal Power Interaction Plot', 'Humidity', '5 Miles', '10 Miles', 'Low', 'High']\n",
    "\n",
    "interaction_Plots_var(all_data, group_List, label_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interaction_Plot_Labels():\n",
    "    '''Returns a list of labels for an interaction plot'''\n",
    "    label_List = []\n",
    "    \n",
    "    plot1_xlabel = input('What is the x label for the first graph? ')\n",
    "    label_List.append(plot1_xlabel)\n",
    "    \n",
    "    plots_ylabel = input('What is the y label for the graphs? ')\n",
    "    label_List.append(plots_ylabel)\n",
    "    \n",
    "    plot1_line1 = input('What does the first line of the first graph represent? ')\n",
    "    label_List.append(plot1_line1)\n",
    "    \n",
    "    plot1_line2 = input('What does the second line of the first graph represent? ')\n",
    "    label_List.append(plot1_line2)\n",
    "    \n",
    "    plot1_x1 = input('What is the first x position for the first graph? ')\n",
    "    label_List.append(plot1_x1)\n",
    "    \n",
    "    plot1_x2 = input('What is the second x position for the first graph? ')\n",
    "    label_List.append(plot1_x2)\n",
    "    \n",
    "    plot_title = input('What is the title for the plots? ')\n",
    "    label_List.append(plot_title)\n",
    "    \n",
    "    plot2_xlabel = input('What is the x label for the second graph? ')\n",
    "    label_List.append(plot2_xlabel)\n",
    "    \n",
    "    plot2_line1 = input('What does the first line of the second graph represent? ')\n",
    "    label_List.append(plot2_line1)\n",
    "    \n",
    "    plot2_line2 = input('What does the second line of the second graph represent? ')\n",
    "    label_List.append(plot2_line2)\n",
    "    \n",
    "    plot2_x1 = input('What is the first x position for the second graph? ')\n",
    "    label_List.append(plot2_x1)\n",
    "    \n",
    "    plot2_x2 = input('What is the second x position for the second graph? ')\n",
    "    label_List.append(plot2_x2)\n",
    "    \n",
    "    return label_List\n",
    "\n",
    "labelList = interaction_Plot_Labels()\n",
    "print(labelList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    '''Finds the confidence intervals to 95% of a set of data'''\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.nanmean(a), stats.sem(a, nan_policy='omit')\n",
    "    h = se * stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return h\n",
    "\n",
    "confid_int = mean_confidence_interval(all_data)\n",
    "print(confid_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_runs_var_with_confid_int(data, runList, colorList):\n",
    "    '''Plots data with the respective confidence intervals'''\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    confid_int = mean_confidence_interval(all_data)\n",
    "    match_List = list(data.columns)\n",
    "    \n",
    "    for i in range(len(runList)):\n",
    "        plot_data = data.copy()\n",
    "        run_use = valid_points(all_data, runList[i])\n",
    "        plot_data.insert(1, \"run_use\", run_use)\n",
    "        match_num = match_List.index(runList[i])\n",
    "        ax.scatter(plot_data.index[plot_data.run_use],plot_data[runList[i]][plot_data.run_use], color=colorList[i])\n",
    "        ax.errorbar(plot_data.index[plot_data.run_use], plot_data[runList[i]][plot_data.run_use], yerr = confid_int[match_num], ecolor=colorList[i], linestyle=\"None\")\n",
    "        \n",
    "    ax.set_xlabel('Frequency (kHz)')\n",
    "    ax.set_ylabel('Signal Strength (dBm)')\n",
    "    fig.suptitle('Frequency vs Signal Strength')\n",
    "    plt.legend(runList)\n",
    "    plt.show()\n",
    "\n",
    "run_List = ['Run 11', 'Run 5', 'Run 18', 'Run 2', 'Run 7']\n",
    "color_List = ['b', 'r', 'g', 'c', 'm']\n",
    "\n",
    "plot_runs_var_with_confid_int(all_data, run_List, color_List)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Way ANOVA code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANOVA_oneway_func(data, compare_List):\n",
    "    '''Return an ANOVA one-way evaluation of two data sets (currently only works on two specific sets at a time)'''\n",
    "    # to not mix in nans\n",
    "    use_data = data.copy()\n",
    "    run_use1 = valid_points(all_data, compare_List[0])\n",
    "    use_data.insert(1, \"run_use1\", run_use1)\n",
    "    run_use2 = valid_points(all_data, compare_List[1])\n",
    "    use_data.insert(2, \"run_use2\", run_use2)\n",
    "    \n",
    "    f_val, p_val = stats.f_oneway(data[compare_List[0]][use_data.run_use1], data[compare_List[1]][use_data.run_use2])\n",
    "    \n",
    "    # if the p value is less than 0.05, there is significant statistical difference\n",
    "    if p_val < 0.05:\n",
    "        return print('We reject null hypothesis for ' + compare_List[0] + ' and ' + compare_List[1] + ' due to significant statistical differences shown by a p-value of ' + str(p_val) +'.')\n",
    "    else:\n",
    "        return print('We fail to reject null hypothesis for ' + compare_List[0] + ' and ' + compare_List[1] + ' due to lacking significant statistical differences shown by a p-value of ' + str(p_val) +'.')\n",
    "\n",
    "# result is as expected\n",
    "compareList = ['Run 1', 'Run 16']\n",
    "ANOVA_oneway_func(all_data, compareList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirms that humidity has a lesser impact than distance\n",
    "compareList = ['Run 1', 'Run 11']\n",
    "ANOVA_oneway_func(all_data, compareList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recognizes that the two are part of the same set\n",
    "compareList = ['Run 1', 'Run 2']\n",
    "ANOVA_oneway_func(all_data, compareList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result is as expected\n",
    "compareList = ['Run 1', 'Run 6']\n",
    "ANOVA_oneway_func(all_data, compareList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANOVA_oneway_func_multi_runs(data, compare_List):\n",
    "    # to not mix in nans\n",
    "    group_a = []\n",
    "    group_b = []\n",
    "    \n",
    "    for i in compare_List[0]:\n",
    "        for j in data[i]:\n",
    "            if pd.notna(j):\n",
    "                group_a.append(j)\n",
    "    \n",
    "    for i in compare_List[1]:\n",
    "        for j in data[i]:\n",
    "            if pd.notna(j):\n",
    "                group_b.append(j)\n",
    "                \n",
    "    \n",
    "    f_val, p_val = stats.f_oneway(group_a, group_b)\n",
    "    \n",
    "    # if the p value is less than 0.05, there is significant statistical difference\n",
    "    if p_val < 0.05:\n",
    "        return print('We reject null hypothesis for the two groups of data due to significant statistical differences shown by a p-value of ' + str(p_val) +'.')\n",
    "    else:\n",
    "        return print('We fail to reject null hypothesis for for the two groups of data due to lacking significant statistical differences shown by a p-value of ' + str(p_val) +'.')\n",
    "\n",
    "# result is as expected\n",
    "compareList = [['Run 1', 'Run 2', 'Run 3', 'Run 4', 'Run 5'], ['Run 16', 'Run 17', 'Run 18', 'Run 19', 'Run 20']]\n",
    "ANOVA_oneway_func_multi_runs(all_data, compareList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compareList = [['Run 1', 'Run 2', 'Run 3', 'Run 4', 'Run 5'], ['Run 11', 'Run 12', 'Run 13', 'Run 14', 'Run 15']]\n",
    "ANOVA_oneway_func_multi_runs(all_data, compareList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compareList = [['Run 1', 'Run 2', 'Run 3', 'Run 4', 'Run 5'], ['Run 6', 'Run 7', ' Run 8', 'Run 9', 'Run 10']]\n",
    "ANOVA_oneway_func_multi_runs(all_data, compareList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-Way ANOVA code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANOVA_twoway_func(data, group_Lists_a, group_Lists_b):\n",
    "    \n",
    "    group_a_1 = []\n",
    "    for i in group_Lists_a[0]:\n",
    "        for j in data[i]:\n",
    "            if pd.notna(j):\n",
    "                group_a_1.append(j)\n",
    "    \n",
    "    group_a_2 = []\n",
    "    for i in group_Lists_a[1]:\n",
    "        for j in data[i]:\n",
    "            if pd.notna(j):\n",
    "                group_a_2.append(j)\n",
    "    group_b_1 = []\n",
    "    for i in group_Lists_b[0]:\n",
    "        for j in data[i]:\n",
    "            if pd.notna(j):\n",
    "                group_b_1.append(j)\n",
    "    \n",
    "    group_b_2 = []\n",
    "    for i in group_Lists_b[1]:\n",
    "        for j in data[i]:\n",
    "            if pd.notna(j):\n",
    "                group_b_2.append(j)\n",
    "    \n",
    "    group_sum = 0\n",
    "    group_count = 0\n",
    "    for i in group_Lists_a[0]:\n",
    "        if i in group_Lists_b[0]:\n",
    "            for j in data[i]:\n",
    "                if pd.notna(j):\n",
    "                    group_sum = group_sum + j\n",
    "                    group_count = group_count + 1\n",
    "    group1_mean = group_sum/group_count\n",
    "    \n",
    "    group_sum = 0\n",
    "    group_count = 0\n",
    "    for i in group_Lists_a[0]:\n",
    "        if i in group_Lists_b[1]:\n",
    "            for j in data[i]:\n",
    "                if pd.notna(j):\n",
    "                    group_sum = group_sum + j\n",
    "                    group_count = group_count + 1\n",
    "    group2_mean = group_sum/group_count\n",
    "    \n",
    "    group_sum = 0\n",
    "    group_count = 0\n",
    "    for i in group_Lists_a[1]:\n",
    "        if i in group_Lists_b[0]:\n",
    "            for j in data[i]:\n",
    "                if pd.notna(j):\n",
    "                    group_sum = group_sum + j\n",
    "                    group_count = group_count + 1\n",
    "    group3_mean = group_sum/group_count\n",
    "    \n",
    "    group_sum = 0\n",
    "    group_count = 0\n",
    "    for i in group_Lists_a[1]:\n",
    "        if i in group_Lists_b[1]:\n",
    "            for j in data[i]:\n",
    "                if pd.notna(j):\n",
    "                    group_sum = group_sum + j\n",
    "                    group_count = group_count + 1\n",
    "    group4_mean = group_sum/group_count\n",
    "     \n",
    "    df_a = len(group_Lists_a) - 1\n",
    "    df_b = len(group_Lists_b) - 1\n",
    "    df_axb = df_a * df_b\n",
    "    df_w = (len(group_a_1) + len(group_a_2) + len(group_b_1) + len(group_b_2)) - ((df_a+1)*(df_b+1))\n",
    "    \n",
    "    mean_total = (sum(group_a_1) + sum(group_a_2) + sum(group_b_1) + sum(group_b_2))/(len(group_a_1) + len(group_a_2) + len(group_b_1) + len(group_b_2))\n",
    "    print(mean_total)\n",
    "    ss_total = 0\n",
    "    for i in range(0, len(group_a_1)): #all groups should be the same length\n",
    "        ss_total = ss_total + (group_a_1[i] - mean_total)**2 + (group_a_2[i] - mean_total)**2\n",
    "    \n",
    "    ss_a = ((sum(group_a_1)/len(group_a_1)) - mean_total)**2 + ((sum(group_a_2)/len(group_a_2)) - mean_total)**2\n",
    "    print(ss_total)\n",
    "    ss_b = ((sum(group_b_1)/len(group_b_1)) - mean_total)**2 + ((sum(group_b_2)/len(group_b_2)) - mean_total)**2\n",
    "    ss_axb = (group1_mean - (sum(group_a_1)/len(group_a_1)) - (sum(group_b_1)/len(group_b_1)) + mean_total)**2 + (group2_mean - (sum(group_a_1)/len(group_a_1)) - (sum(group_b_2)/len(group_b_2)) + mean_total)**2 + (group3_mean - (sum(group_a_2)/len(group_a_2)) - (sum(group_b_1)/len(group_b_1)) + mean_total)**2 + (group4_mean - (sum(group_a_2)/len(group_a_2)) - (sum(group_b_2)/len(group_b_2)) + mean_total)**2\n",
    "    ss_w = ss_total - ss_a - ss_b - ss_axb\n",
    "    \n",
    "    MS_a = ss_a/df_a #before here\n",
    "    MS_b = ss_b/df_b\n",
    "    MS_axb = ss_axb/df_axb\n",
    "    MS_w = ss_w/df_w\n",
    "    \n",
    "    f_val_a = MS_a/MS_w\n",
    "    f_val_b = MS_b/MS_w\n",
    "    f_val_axb = MS_axb/MS_w\n",
    "    \n",
    "    p_a = stats.f.sf(f_val_a, df_a, df_w)\n",
    "    p_b = stats.f.sf(f_val_b, df_b, df_w)\n",
    "    p_axb = stats.f.sf(f_val_axb, df_axb, df_w)\n",
    "    \n",
    "    \n",
    "    return p_a, p_b, p_axb\n",
    "groupLists1 = [['Run 1', 'Run 2', 'Run 3', 'Run 4', 'Run 5', 'Run 6', 'Run 7', ' Run 8', 'Run 9', 'Run 10'], ['Run 11', 'Run 12', 'Run 13', 'Run 14', 'Run 15', 'Run 16', 'Run 17', 'Run 18', 'Run 19', 'Run 20']]\n",
    "groupLists2 = [['Run 1', 'Run 2', 'Run 3', 'Run 4', 'Run 5', 'Run 11', 'Run 12', 'Run 13', 'Run 14', 'Run 15'], ['Run 6', 'Run 7', ' Run 8', 'Run 9', 'Run 10', 'Run 16', 'Run 17', 'Run 18', 'Run 19', 'Run 20']]\n",
    "\n",
    "p_a_val, p_b_val, p_axb_val = ANOVA_twoway_func(all_data, groupLists1, groupLists2)\n",
    "print(p_a_val)\n",
    "print(p_b_val)\n",
    "print(p_axb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.sum(axis=0,skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sum = all_data.sum(axis=0,skipna=True)\n",
    "print(sum(run_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANOVA_twoway_func_Line(data):\n",
    "    N = len(data.Power)\n",
    "    df_a = len(data.Distance.unique()) - 1\n",
    "    df_b = len(data.Humidity.unique()) - 1\n",
    "    df_axb = df_a*df_b \n",
    "    df_w = N - (len(data.Distance.unique())*len(data.Humidity.unique()))\n",
    "    \n",
    "    grand_mean = data['Power'].mean()\n",
    "    \n",
    "    ssq_a = sum([(data[data.Distance ==l].Power.mean()-grand_mean)**2 for l in data.Distance])\n",
    "    ssq_b = sum([(data[data.Humidity ==l].Power.mean()-grand_mean)**2 for l in data.Humidity])\n",
    "    ssq_t = sum((data.Power - grand_mean)**2)\n",
    "    \n",
    "    short_dist = data[data.Distance == 5]\n",
    "    long_dist = data[data.Distance == 10]\n",
    "    short_dist_means = [short_dist[short_dist.Humidity == d].Power.mean() for d in short_dist.Humidity]\n",
    "    long_dist_means = [long_dist[long_dist.Humidity == d].Power.mean() for d in long_dist.Humidity]\n",
    "    ssq_w = sum((long_dist.Power - long_dist_means)**2) + sum((short_dist.Power - short_dist_means)**2)\n",
    "    \n",
    "    ssq_axb = ssq_t - ssq_a - ssq_b - ssq_w\n",
    "    \n",
    "    ms_a = ssq_a/df_a\n",
    "    ms_b = ssq_b/df_b\n",
    "    ms_axb = ssq_axb/df_axb\n",
    "    ms_w = ssq_w/df_w\n",
    "    \n",
    "    f_a = ms_a/ms_w\n",
    "    f_b = ms_b/ms_w\n",
    "    f_axb = ms_axb/ms_w\n",
    "    \n",
    "    p_a = stats.f.sf(f_a, df_a, df_w)\n",
    "    p_b = stats.f.sf(f_b, df_b, df_w)\n",
    "    p_axb = stats.f.sf(f_axb, df_axb, df_w)\n",
    "    \n",
    "    return p_a, p_b, p_axb\n",
    "    \n",
    "line_data = pd.read_excel(\"FM Radio Signal Strength dra.xlsx\")\n",
    "p_a_val, p_b_val, p_axb_val = ANOVA_twoway_func_Line(line_data)\n",
    "print(p_a_val)\n",
    "print(p_b_val)\n",
    "print(p_axb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_input():\n",
    "    cont_file = True\n",
    "    data = {}\n",
    "    fileName = input('What is the name of the json file? ')\n",
    "    section_num = int(input('How many key/value pairs are there? '))\n",
    "    \n",
    "    for i in range(0, section_num):\n",
    "        key_type = input('Is the key a integer or string? (int/str) ')\n",
    "        if key_type == 'int':\n",
    "            key_name = int(input('Input key: '))\n",
    "        elif key_type == 'str':\n",
    "            key_name = str(input('Input key: '))\n",
    "            \n",
    "        value_type = input('Is the value a single item or a list? (Single/List) ')\n",
    "        if value_type == 'Single':\n",
    "            type_value = input('Is the key a integer, list, or string? (int/lst/str) ')\n",
    "            if type_value == 'int':\n",
    "                value_item = int(input('What is the value for the key? '))\n",
    "            elif type_value == 'lst':\n",
    "                elements_num = int(input('How long is this list? '))\n",
    "                value_item = []\n",
    "                for elem_num in range(0, elements_num):\n",
    "                    value_item_type = input('Element type? (int/str) ')\n",
    "                    if value_item_type == 'int':\n",
    "                        value_item.append(int(input('Element in value list? ')))\n",
    "                    elif value_item_type == 'str':\n",
    "                        value_item.append(str(input('Element in value list? ')))\n",
    "            elif type_value == 'str':\n",
    "                value_item = str(input('What is the value for this key? '))\n",
    "            data[key_name] = value_item\n",
    "            \n",
    "        if value_type == 'List':\n",
    "            value_List = []\n",
    "            list_len = int(input('How many dictionaries are in the list? '))\n",
    "            for j in range(0, list_len):\n",
    "                list_dict = {}\n",
    "                dict_len = int(input('How many key/value pairs are there in this dictionary? '))\n",
    "                for k in range(0, dict_len):\n",
    "                    key_type_list = input('Is the key a integer or string? (int/str) ')\n",
    "                    if key_type_list == 'int':\n",
    "                        key_name_list = int(input('Input key: '))\n",
    "                    elif key_type_list == 'str':\n",
    "                        key_name_list = str(input('Input key: '))\n",
    "                    type_value = input('Is the key a integer, list, or string? (int/lst/str) ')\n",
    "                    if type_value == 'int':\n",
    "                        key_value = int(input('What is the value for this key? '))\n",
    "                    elif type_value == 'lst':\n",
    "                        key_value = [int(x) for x in input('What are the values for the key? (Values should be separated by commas)').split(\",\")]\n",
    "                    elif type_value == 'str':\n",
    "                        key_value = str(input('What is the value for this key? '))\n",
    "                    list_dict[key_name_list] = key_value\n",
    "                value_List.append(list_dict)\n",
    "            data[key_name] = value_List\n",
    "        \n",
    "    with open(fileName, 'w') as outfile:\n",
    "        json.dump(data, outfile, indent=4, sort_keys=True, separators=(', ',':'))\n",
    "\n",
    "        \n",
    "json_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python input forms\n",
    "x = [int(x) for x in input(\"Enter multiple value: \").split(\",\")] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for choosing data type\n",
    "\n",
    "def input_type(item):\n",
    "    try:\n",
    "        int_item = int(item)\n",
    "        return int_item\n",
    "    except ValueError:\n",
    "        return item\n",
    "\n",
    "print(type(input_type('three')))\n",
    "print(type(input_type('3')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_input_ver2():\n",
    "    cont_file = True\n",
    "    data = {}\n",
    "    fileName = input('What is the name of the json file? ')\n",
    "    section_num = int(input('How many key/value pairs are there? '))\n",
    "    \n",
    "    for i in range(section_num):\n",
    "        key_input = input('What is the key?')\n",
    "        key_final = input_type(key_input)\n",
    "        value_type = input('Is the value a single item or a list? (Single/List) ')\n",
    "        if value_type == 'Single':\n",
    "            type_value = input('Is the value a single item or a list? (Single/List) ')\n",
    "            if type_value == 'Single':\n",
    "                value_input = input('What is the value? ')\n",
    "                value_final = input_type(value_input)\n",
    "            elif type_value == 'List':\n",
    "                elements_num = int(input('How long is this list? '))\n",
    "                for elem_num in range(elements_num):\n",
    "                    value_final = [input_type(x) for x in input('What are the values for the key? (Values should be separated by commas) ').split(\",\")]\n",
    "            data[key_final] = value_final\n",
    "            \n",
    "        if value_type == 'List':\n",
    "            value_List = []\n",
    "            list_len = int(input('How many dictionaries are in the list? '))\n",
    "            for j in range(list_len):\n",
    "                list_dict = {}\n",
    "                dict_len = int(input('How many key/value pairs are there in this dictionary? '))\n",
    "                for k in range(dict_len):\n",
    "                    list_key_input = input('What is the key?')\n",
    "                    list_key_final = input_type(list_key_input)\n",
    "                    type_value = input('Is the value a single item or a list? (Single/List) ')\n",
    "                    if type_value == 'Single':\n",
    "                        list_value_input = input_type(input('What is the value for this key? '))\n",
    "                        list_value_final = input_type(list_value_input)\n",
    "                    elif type_value == 'List':\n",
    "                        list_value_final = [input_type(x) for x in input('What are the values for the key? (Values should be separated by commas) ').split(\",\")]\n",
    "                    list_dict[list_key_final] = list_value_final\n",
    "                value_List.append(list_dict)\n",
    "            data[key_final] = value_List\n",
    "        \n",
    "    with open(fileName, 'w') as outfile:\n",
    "        json.dump(data, outfile, indent=4, sort_keys=True, separators=(', ',':'))\n",
    "\n",
    "        \n",
    "json_input_ver2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['player' 'pos' 'age' 'bref_team_id' 'g' 'gs' 'mp' 'fg' 'fga' 'fg.' 'x3p'\n",
      " 'x3pa' 'x3p.' 'x2p' 'x2pa' 'x2p.' 'efg.' 'ft' 'fta' 'ft.' 'orb' 'drb'\n",
      " 'trb' 'ast' 'stl' 'blk' 'tov' 'pf' 'pts' 'season' 'season_end']\n",
      "Predicted values (pts): \n",
      "994.8, 1920.6, 768.0, 84.8, 1294.8, 589.4, 1140.8, 87.0, 639.4, 297.0, 694.6, 514.6, 1028.4, 900.8, 807.6, 252.6, 179.2, 1043.2, 31.6, 355.0, 406.6, 893.0, 79.6, 595.0, 186.6, 279.8, 11.6, 169.0, 420.0, 784.4, 704.2, 56.4, 555.6, 407.2, 313.0, 576.2, 294.0, 1609.0, 502.4, 1369.8, 817.0, 994.0, 1096.6, 156.8, 439.2, 814.6, 12.6, 1274.0, 532.2, 786.0, 551.4, 275.4, 635.8, 1270.8, 869.0, 172.0, 1042.0, 551.6, 1513.4, 76.6, 368.2, 760.6, 84.0, 334.4, 395.0, 1070.4, 18.2, 474.6, 818.2, 33.6, 203.8, 696.4, 438.6, 571.4, 319.8, 826.2, 235.6, 1048.2, 116.0, 1403.4, 367.8, 195.8, 914.0, 59.0, 619.2, 619.8, 68.0, 407.0, 269.4, 15.2, 420.0, 966.0, 802.2, 766.4, 598.6, 27.4, 457.0, 129.0, 1046.6, 251.0, 784.2, 99.4, 849.4, 356.2, 548.6, 1146.0, 130.8, 446.4, 571.0, 1351.6, 424.2, 1235.8, 1265.8, 535.0, 178.6, 747.0, 66.8, 688.4, 164.6, 11.6, 360.8, 82.6, 1021.0, 106.6, 197.8, 1367.2, 699.2, 198.0, 19.0, 823.2, 37.6, 319.6, 698.6\n",
      "Actual values (pts): \n",
      "1144, 2010, 824, 97, 1291, 624, 1080, 107, 763, 315, 767, 480, 1185, 871, 759, 250, 138, 987, 32, 315, 432, 879, 93, 665, 194, 329, 0, 178, 403, 661, 677, 47, 603, 272, 268, 701, 283, 1603, 579, 1478, 915, 1115, 1042, 183, 548, 715, 9, 1382, 607, 720, 638, 248, 546, 1256, 890, 164, 1068, 511, 1594, 74, 399, 666, 82, 341, 298, 1069, 22, 435, 893, 48, 183, 717, 457, 495, 280, 850, 352, 1095, 79, 1241, 485, 200, 814, 83, 629, 703, 84, 338, 312, 15, 416, 939, 844, 820, 454, 12, 448, 100, 1209, 216, 760, 78, 930, 350, 618, 1106, 98, 401, 587, 1488, 378, 1249, 1330, 529, 137, 796, 71, 770, 177, 1, 339, 68, 1042, 65, 201, 1417, 821, 206, 26, 810, 26, 347, 645\n",
      "Mean squared error:  3935.9587969924814\n"
     ]
    }
   ],
   "source": [
    "#k-nearest; origin: https://www.dataquest.io/blog/k-nearest-neighbors-in-python/\n",
    "import math\n",
    "import pandas\n",
    "with open(\"nba_2013.csv\", 'r') as csvfile:\n",
    "    nba_df = pandas.read_csv(csvfile)\n",
    "print(nba_df.columns.values) # The names of all the columns in the data.\n",
    "\n",
    "# Select Lebron James from our dataset\n",
    "selected_player = nba_df[nba_df[\"player\"] == \"LeBron James\"].iloc[0]\n",
    "\n",
    "# Choose only the numeric columns (we'll use these to compute euclidean distance)\n",
    "distance_columns = ['age', 'g', 'gs', 'mp', 'fg', 'fga', 'fg.', 'x3p', 'x3pa', 'x3p.', 'x2p', 'x2pa', 'x2p.', 'efg.', 'ft', 'fta', 'ft.', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts']\n",
    "\n",
    "#clearing NA values\n",
    "nba = nba_df.dropna()\n",
    "\n",
    "def euclidean_distance(row):\n",
    "    \"\"\"\n",
    "    A simple euclidean distance function\n",
    "    \"\"\"\n",
    "    inner_value = 0\n",
    "    for k in distance_columns:\n",
    "        inner_value += (row[k] - selected_player[k]) ** 2\n",
    "    return math.sqrt(inner_value)\n",
    "\n",
    "# Find the distance from each player in the dataset to lebron.\n",
    "lebron_distance = nba.apply(euclidean_distance, axis=1)\n",
    "\n",
    "# Select only the numeric columns from the NBA dataset\n",
    "nba_numeric = nba[distance_columns]\n",
    "# Normalize all of the numeric columns\n",
    "nba_normalized = (nba_numeric - nba_numeric.mean()) / nba_numeric.std()\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Fill in NA values in nba_normalized\n",
    "nba_normalized.fillna(0, inplace=True)\n",
    "\n",
    "# Find the normalized vector for lebron james.\n",
    "lebron_normalized = nba_normalized[nba[\"player\"] == \"LeBron James\"]\n",
    "\n",
    "# Find the distance between lebron james and everyone else.\n",
    "euclidean_distances = nba_normalized.apply(lambda row: distance.euclidean(row, lebron_normalized), axis=1)\n",
    "\n",
    "# Create a new dataframe with distances.\n",
    "distance_frame = pandas.DataFrame(data={\"dist\": euclidean_distances, \"idx\": euclidean_distances.index})\n",
    "distance_frame.sort_values(by=[\"dist\"], inplace=True)\n",
    "# Find the most similar player to lebron (the lowest distance to lebron is lebron, the second smallest is the most similar non-lebron player)\n",
    "second_smallest = distance_frame.iloc[1][\"idx\"]\n",
    "most_similar_to_lebron = nba.loc[int(second_smallest)][\"player\"]\n",
    "\n",
    "import random\n",
    "from numpy.random import permutation\n",
    "\n",
    "# Randomly shuffle the index of nba.\n",
    "random_indices = permutation(nba.index)\n",
    "\n",
    "# Set a cutoff for how many items we want in the test set (in this case 1/3 of the items)\n",
    "test_cutoff = math.floor(len(nba)/3)\n",
    "\n",
    "# Generate the test set by taking the first 1/3 of the randomly shuffled indices.\n",
    "test = nba.loc[random_indices[1:test_cutoff]]\n",
    "\n",
    "# Generate the train set with the rest of the data.\n",
    "train = nba.loc[random_indices[test_cutoff:]]\n",
    "\n",
    "# The columns that we will be making predictions with.\n",
    "x_columns = ['age', 'g', 'gs', 'mp', 'fg', 'fga', 'fg.', 'x3p', 'x3pa', 'x3p.', 'x2p', 'x2pa', 'x2p.', 'efg.', 'ft', 'fta', 'ft.', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf']\n",
    "# The column that we want to predict.\n",
    "y_column = [\"pts\"]\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# Create the knn model.\n",
    "# Look at the five closest neighbors.\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "# Fit the model on the training data.\n",
    "knn.fit(train[x_columns], train[y_column])\n",
    "# Make point predictions on the test set using the fit model.\n",
    "predictions = knn.predict(test[x_columns])\n",
    "\n",
    "# Get the actual values for the test set.\n",
    "actual = test[y_column]\n",
    "\n",
    "# Compute the mean squared error of our predictions.\n",
    "mse = (((predictions - actual) ** 2).sum()) / len(predictions)\n",
    "\n",
    "#print predicted values\n",
    "predictions_List = [item for sublist in predictions for item in sublist]\n",
    "print('Predicted values (pts): ')\n",
    "print(*predictions_List, sep=\", \")\n",
    "\n",
    "#print actual values\n",
    "actual_List = actual.to_string(header=False,index=False,index_names=False).split(sep='\\n ')\n",
    "actual_print = []\n",
    "for element in actual_List:\n",
    "    actual_print.append(element.strip())\n",
    "\n",
    "print('Actual values (pts): ')\n",
    "print(*actual_print, sep=\", \")\n",
    "\n",
    "#print the mean squared error\n",
    "print('Mean squared error: ', float(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: \n",
      "1815.8, 1048.6, 676.4, 1000.8, 157.4, 456.2, 725.2, 308.8, 571.2, 1064.6, 120.8, 430.8, 188.6, 965.2, 334.4, 394.8, 918.6, 872.8, 1053.8, 179.6, 1073.8, 1344.6, 11.2, 12.0, 1436.6, 224.6, 101.4, 1090.4, 774.6, 964.2, 756.6, 1263.6, 189.8, 75.6, 344.6, 321.0, 1095.2, 1098.4, 515.8, 835.4, 7.0, 101.4, 1726.8, 331.0, 1204.6, 1085.0, 464.2, 168.0, 6.0, 81.6, 1128.4, 841.4, 7.0, 676.6, 349.6, 289.6, 192.2, 396.4, 1419.4, 226.4, 65.0, 651.0, 302.6, 1323.8, 203.4, 239.8, 613.2, 370.4, 806.2, 559.4, 328.4, 101.6, 191.0, 1356.8, 364.8, 808.4, 654.4, 312.6, 912.8, 179.2, 825.0, 404.6, 7.0, 867.4, 144.2, 25.6, 964.0, 15.8, 560.4, 119.4, 1387.4, 27.0, 189.8, 1092.6, 81.6, 467.4, 433.6, 481.8, 88.2, 417.2, 89.8, 30.0, 1729.4, 92.2, 38.6, 545.4, 1208.6, 361.0, 576.4, 42.6, 582.8, 934.0, 666.6, 651.8, 101.4, 843.2, 651.0, 1101.0, 60.6, 808.4, 553.8, 421.2, 411.2, 1971.4, 997.2, 685.4, 921.0, 1049.8, 55.8, 344.6, 851.4, 34.4, 429.4\n",
      "Actual values: \n",
      "1791, 1069, 703, 982, 132, 378, 821, 343, 625, 1185, 143, 485, 208, 1090, 341, 298, 891, 890, 1068, 178, 1071, 1241, 22, 26, 1417, 270, 110, 1282, 810, 1041, 716, 1167, 200, 76, 339, 261, 1047, 1298, 403, 666, 14, 145, 1737, 436, 1226, 1007, 448, 137, 5, 75, 1095, 844, 14, 572, 404, 306, 273, 393, 1614, 217, 73, 838, 283, 1382, 181, 257, 717, 404, 925, 607, 347, 115, 201, 1542, 272, 715, 527, 315, 895, 191, 820, 432, 19, 1010, 140, 18, 871, 26, 636, 159, 1372, 29, 183, 1068, 74, 548, 477, 490, 136, 538, 78, 33, 1930, 153, 47, 579, 1131, 346, 603, 43, 587, 1144, 677, 826, 136, 791, 660, 1209, 71, 720, 608, 298, 416, 2010, 1028, 666, 781, 1096, 68, 252, 779, 39, 401\n",
      "Mean squared error:  5349.395488721803\n"
     ]
    }
   ],
   "source": [
    "def knearest_analysis(data, x_columns, y_column):\n",
    "    import random\n",
    "    from numpy.random import permutation\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    \n",
    "    # Randomly shuffle the index of nba.\n",
    "    random_indices = permutation(data.index)\n",
    "    \n",
    "    # Set a cutoff for how many items we want in the test set (in this case 1/3 of the items)\n",
    "    test_cutoff = math.floor(len(data)/3)\n",
    "    \n",
    "    # Generate the test set by taking the first 1/3 of the randomly shuffled indices.\n",
    "    test = data.loc[random_indices[1:test_cutoff]]\n",
    "    \n",
    "    # Generate the train set with the rest of the data.\n",
    "    train = data.loc[random_indices[test_cutoff:]]\n",
    "    \n",
    "    # Create the knn model.\n",
    "    # Look at the five closest neighbors.\n",
    "    knn = KNeighborsRegressor(n_neighbors=5)\n",
    "    # Fit the model on the training data.\n",
    "    knn.fit(train[x_columns], train[y_column])\n",
    "    # Make point predictions on the test set using the fit model.\n",
    "    predictions = knn.predict(test[x_columns])\n",
    "    # Get the actual values for the test set.\n",
    "    actual = test[y_column]\n",
    "    \n",
    "    # Compute the mean squared error of our predictions.\n",
    "    mse = (((predictions - actual) ** 2).sum()) / len(predictions)\n",
    "    \n",
    "    #print predicted values\n",
    "    predictions_List = [item for sublist in predictions for item in sublist]\n",
    "    print('Predicted values: ')\n",
    "    print(*predictions_List, sep=\", \")\n",
    "    \n",
    "    #print actual values\n",
    "    actual_List = actual.to_string(header=False,index=False,index_names=False).split(sep='\\n ')\n",
    "    actual_print = []\n",
    "    for element in actual_List:\n",
    "        actual_print.append(element.strip())\n",
    "        \n",
    "    print('Actual values: ')\n",
    "    print(*actual_print, sep=\", \")\n",
    "    \n",
    "    #print the mean squared error\n",
    "    print('Mean squared error: ', float(mse))\n",
    "    \n",
    "x_columns_test = ['age', 'g', 'gs', 'mp', 'fg', 'fga', 'fg.', 'x3p', 'x3pa', 'x3p.', 'x2p', 'x2pa', 'x2p.', 'efg.', 'ft', 'fta', 'ft.', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf']\n",
    "# The column that we want to predict.\n",
    "y_column_test = [\"pts\"]\n",
    "\n",
    "knearest_analysis(nba, x_columns_test, y_column_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# py qt; requires some hard coding\n",
    "\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QInputDialog, QLineEdit\n",
    "\n",
    "def pyqt_input_col_len_5(num_of_col):\n",
    "    title_List = []\n",
    "    all_rows_List = []\n",
    "    for i in range(num_of_col):\n",
    "        specific_row_List = []\n",
    "        col_title = QLineEdit()\n",
    "        col_title.setAlignment(Qt.AlignRight)\n",
    "        col_title.setFont(QFont(\"Arial\",20))\n",
    "        row1 = QLineEdit()\n",
    "        \n",
    "        flo = QFormLayout()\n",
    "        flo.addRow(\"Column Title\", col_title)\n",
    "        flo.addRow(\"First Row\",row1)\n",
    "        \n",
    "        row2 = QLineEdit()\n",
    "        flo.addRow(\"Second Row\",row2)\n",
    "        \n",
    "        row3 = QLineEdit()\n",
    "        flo.addRow(\"Third Row\",row3)\n",
    "        \n",
    "        row4 = QLineEdit()\n",
    "        flo.addRow(\"Fourth Row\",row4)\n",
    "        \n",
    "        row5 = QLineEdit()\n",
    "        flo.addRow(\"Fifth Row\",row5)\n",
    "        \n",
    "        specific_row_List.append(row1)\n",
    "        specific_row_List.append(row2)\n",
    "        specific_row_List.append(row3)\n",
    "        specific_row_List.append(row4)\n",
    "        specific_row_List.append(row5)\n",
    "        \n",
    "        title_List.append(str(col_title))\n",
    "        all_rows_List.append(specific_row_List)\n",
    "        \n",
    "    data = {title_List[0]:all_rows_List[0]}\n",
    "    df = pd.dataframe(data)\n",
    "    title_List = title_List[1:]\n",
    "    all_rows_List = all_rows_List[1:]\n",
    "    for i in title_List:\n",
    "        df[title_List[i]] = all_rows_List[0]\n",
    "        all_rows_List = all_rows_List[1:]\n",
    "    return df\n",
    "\n",
    "df = pyqt_input_col_len_5(3)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
